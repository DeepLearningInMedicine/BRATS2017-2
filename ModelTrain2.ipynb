{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "from nibabel.testing import data_path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data feeding function\n",
    "\n",
    "def trainDatafeed(batch_size):\n",
    "    \"\"\"\n",
    "    Generate training batches for the BRATS data\n",
    "    \n",
    "    The image resizing is done as follows:\n",
    "        - 40 slices removed from beginning and end of dims 0 and 1\n",
    "        - 4 removed from start and 7 removed from end of dim 2\n",
    "        - Image futher downsampled via mean pooling at beginning of CNN\n",
    "    \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    j = 0\n",
    "    inds = np.random.randint(1, 255, batch_size)\n",
    "    \n",
    "    inData = np.zeros((batch_size,160,160,144,4))\n",
    "    labelData = np.zeros((batch_size,160,160,144,5))\n",
    "    yFull = np.zeros((batch_size,240,240,155))\n",
    "    \n",
    "    for root, dirs, files in os.walk('../HGG/'):\n",
    "        if (j>=batch_size):\n",
    "            break\n",
    "        if (i < 190) and (len(files) > 1) and (i==inds[j]): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            yFull[j,:,:,:] = seg_img\n",
    "            \n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            \n",
    "            j+= 1\n",
    "        i +=1 \n",
    "        \n",
    "    for root, dirs, files in os.walk('../LGG/'):\n",
    "        if (j>=batch_size):\n",
    "            break\n",
    "        if (i - 190 <65) and (len(files) > 1) and (i==inds[j]): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            yFull[j,:,:,:] = seg_img\n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            j+= 1\n",
    "        i +=1\n",
    "    \n",
    "    x = inData\n",
    "    y = labelData.reshape([-1,160*160*144*5])\n",
    "    \n",
    "    return x, y, yFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valDatafeed():\n",
    "    \"\"\"\n",
    "    Generate validation batches for the BRATS data\n",
    "    \n",
    "    The image resizing is done as follows (same as in training):\n",
    "        - 40 slices removed from beginning and end of dims 0 and 1\n",
    "        - 4 removed from start and 7 removed from end of dim 2\n",
    "        - Image futher downsampled via mean pooling at beginning of CNN\n",
    "    \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    inData = np.zeros((30,160,160,144,4))\n",
    "    labelData = np.zeros((30,160,160,144,5))\n",
    "    yFull = np.zeros((30,240,240,155))\n",
    "    \n",
    "    for root, dirs, files in os.walk('../HGG/'):\n",
    "        if (j>=30):\n",
    "            break\n",
    "        if (i >= 190) and (len(files) > 1): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            yFull[j,:,:,:] = seg_img\n",
    "            \n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            \n",
    "            j+= 1\n",
    "        i +=1 \n",
    "        \n",
    "    for root, dirs, files in os.walk('../LGG/'):\n",
    "        if (j>=30):\n",
    "            break\n",
    "        if (i - 190 >= 65) and (len(files) > 1): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            yFull[j,:,:,:] = seg_img\n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            j+= 1\n",
    "        i +=1\n",
    "    \n",
    "    x = inData\n",
    "    y = labelData.reshape([-1,160*160*144*5])\n",
    "    \n",
    "    return x, y, yFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 240, 240, 155)\n"
     ]
    }
   ],
   "source": [
    "# Test validation data feed\n",
    "x, y, yFull = valDatafeed()\n",
    "print(yFull.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diceCalc(tensor1, tensor2):\n",
    "    #\n",
    "    # Subroutine for calculating dice score of two equal-sized binary tensors\n",
    "    #\n",
    "    \n",
    "    shape = tf.shape(tensor1)\n",
    "    reshape1 = tf.reshape(tensor1,[shape[0],-1])\n",
    "    reshape2 = tf.reshape(tensor2,[shape[0],-1])\n",
    "    \n",
    "    score = 2*tf.reduce_mean(tf.divide(tf.reduce_sum(tf.multiply(reshape1,reshape2),axis=1),\n",
    "                       (tf.reduce_sum(reshape1,axis=1) + tf.reduce_sum(reshape2,axis=1))))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DICEscores(yFull, pred):\n",
    "    #\n",
    "    # truth, estimate = tf tensors of size N x Volume size\n",
    "    # \n",
    "    # Computes Dice scores for each class and overall tumor region\n",
    "    # \n",
    "    \n",
    "    yFullTensor = tf.stack(yFull)\n",
    "    predFull = tf.pad(pred,[[0,0], [40, 40], [40, 40], [4, 7]])\n",
    "    \n",
    "    classScores = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        score = diceCalc(tf.to_float(tf.equal(yFull,i)), tf.to_float(tf.equal(predFull,i)))\n",
    "        classScores.append(score)\n",
    "    \n",
    "    diceScore = diceCalc(tf.to_float(tf.greater(yFull,0)), tf.to_float(tf.greater(predFull,0)))\n",
    "        \n",
    "    return diceScore, classScores[0], classScores[1], classScores[2], classScores[3], classScores[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test DICE Score cell\n",
    "x, y, yFull = BRATSdatafeed(batch_size)\n",
    "pred = tf.argmax(tf.reshape(y,[-1,160,160,144,5]),4)\n",
    "diceScore, score1, score2, score3, score4, score5 = DICEscores(yFull, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 2\n",
    "l2Param = 1e-5\n",
    "\n",
    "inputPlaceholder = tf.placeholder(tf.float32, shape = [batch_size, 160,160,144,4])\n",
    "outputPlaceholder = tf.placeholder(tf.float32, shape = [batch_size, 160*160*144*5])\n",
    "    \n",
    "    \n",
    "x_downsample = tf.layers.average_pooling3d(inputs = inputPlaceholder, pool_size = (2,2,2),\n",
    "                                strides = (2,2,2), padding='valid',name=None)\n",
    "conv1 = tf.layers.conv3d(inputs=x_downsample, filters=8, \n",
    "                         kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling3d(inputs = conv1, pool_size = (2,2,2),\n",
    "                                strides = (2,2,2), padding='valid',name=None)\n",
    "\n",
    "conv2 = tf.layers.conv3d(inputs=pool1, filters=8, \n",
    "                         kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling3d(inputs = conv2, pool_size = (2,2,2),\n",
    "                                strides = (2,2,2), padding='valid',name=None)\n",
    "\n",
    "conv3 = tf.layers.conv3d(inputs=pool2, filters=32, \n",
    "                         kernel_size=[3, 3, 3],padding=\"same\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling3d(inputs = conv3, pool_size = (2,2,2),\n",
    "                                strides = (2,2,2), padding='valid',name=None)\n",
    "\n",
    "conv4 = tf.layers.conv3d(inputs=pool3, filters=128, \n",
    "                         kernel_size=[3, 3, 3],padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "            \n",
    "W4 = tf.Variable(tf.truncated_normal([3, 3, 3, 16, 128], stddev=0.1))\n",
    "deconv4 = tf.nn.conv3d_transpose(conv4, filter = W4, output_shape = [batch_size,20, 20, 18, 16], \n",
    "                                 strides = [1,2,2,2,1])\n",
    "\n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[16]))\n",
    "relu4 = tf.nn.relu(deconv4 + b4)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([3, 3, 3, 8, 16], stddev=0.1))\n",
    "deconv3 = tf.nn.conv3d_transpose(relu4, filter = W3, output_shape = [batch_size,40, 40, 36, 8], \n",
    "                                 strides = [1,2,2,2,1])\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[8]))\n",
    "relu3 = tf.nn.relu(deconv3 + b3)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([3, 3, 3, 8, 8], stddev=0.1))\n",
    "deconv2 = tf.nn.conv3d_transpose(relu3, filter = W2, output_shape = [batch_size,80, 80, 72, 8], \n",
    "                                 strides = [1,2,2,2,1])\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[8]))\n",
    "relu2 = tf.nn.relu(deconv2 + b2)\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([3, 3, 3, 5, 8], stddev=0.1))\n",
    "deconv1 = tf.nn.conv3d_transpose(relu2, filter = W1, output_shape = [batch_size,160, 160, 144, 5], \n",
    "                                 strides = [1,2,2,2,1])\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[5]))\n",
    "scores = tf.reshape(deconv1 + b1,[batch_size,5*160*160*144])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loss and training step    \n",
    "segLoss = tf.reduce_mean(tf.losses.softmax_cross_entropy(outputPlaceholder, scores))\n",
    "regLoss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3) + tf.nn.l2_loss(W4)     \n",
    "loss = segLoss + l2Param*regLoss\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = 1e-3, beta1 = 0.5).minimize(loss)\n",
    "\n",
    "\n",
    "# Set up functions to evaluate accuracy\n",
    "probs = tf.nn.softmax(tf.reshape(scores, [batch_size,160,160,144,5]),dim = 4)\n",
    "prediction = tf.argmax(probs, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activate session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "# Calculate training loop parameters\n",
    "epoch_num = 1\n",
    "iterNum = np.int(np.ceil(255/batch_size * epoch_num))\n",
    "\n",
    "\n",
    "# Run training loop\n",
    "lossList = []\n",
    "diceListTrain = []\n",
    "diceClassListTrain = []\n",
    "diceListVal = []\n",
    "diceClassListVal = []\n",
    "\n",
    "for i in range(iterNum):\n",
    "    x, y, yFull = trainDatafeed(batch_size)\n",
    "    pred, loss, _ = sess.run([prediction, segLoss, train_step], feed_dict={inputPlaceholder: x, outputPlaceholder: y})\n",
    "    \n",
    "    lossList.append(loss.eval())\n",
    "    \n",
    "    groundTruth = tf.convert_to_tensor(np.argmax(y,axis=4))\n",
    "    dice, scoresList = DICEscore(tf.stack(yFull), pred)\n",
    "    score0, score1, score2, score3, score4 = scoresList\n",
    "    \n",
    "    diceListTrain.append(dice)\n",
    "    diceClassListTrain.append([score0, score1, score2, score3, score4])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"Training dice score is: %f\" % dice)\n",
    "        \n",
    "        x, y, yFull = valDatafeed()\n",
    "        pred = sess.run(prediction, feed_dict={inputPlaceholder: x, outputPlaceholder: y})\n",
    "        dice,scoresList = DICEscore(tf.stack(yFull), pred)\n",
    "        score0, score1, score2, score3, score4 = scoresList\n",
    "    \n",
    "        diceListVal.append(dice)\n",
    "        diceClassListVal.append([score0, score1, score2, score3, score4])\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
