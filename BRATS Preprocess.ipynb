{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup -- from CS 231N GANs notebook\n",
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "from nibabel.testing import data_path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A bunch of utility functions\n",
    "\n",
    "def show_images(images):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return\n",
    "\n",
    "def show_multimodal(image):\n",
    "    # images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    figdim = int(np.ceil(image.shape[0]/2))\n",
    "    # sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "    \n",
    "    dispInd = int(np.ceil(image.shape[3]/2))\n",
    "\n",
    "    fig = plt.figure(figsize=(figdim, figdim))\n",
    "    gs = gridspec.GridSpec(figdim, figdim)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(image[i,:,:,dispInd])\n",
    "    return\n",
    "\n",
    "def preprocess_img(x):\n",
    "    return 2 * x - 1.0\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def count_params():\n",
    "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
    "    param_count = np.sum([np.prod(x.get_shape().as_list()) for x in tf.global_variables()])\n",
    "    return param_count\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Open \n",
    "path = '../HGG/Brats17_2013_2_1/Brats17_2013_2_1_flair.nii'\n",
    "flair_img = nib.load(path).get_data()\n",
    "\n",
    "path = '../HGG/Brats17_2013_2_1/Brats17_2013_2_1_t1.nii'\n",
    "t1_img = nib.load(path).get_data()\n",
    "\n",
    "path = '../HGG/Brats17_2013_2_1/Brats17_2013_2_1_t2.nii'\n",
    "t2_img = nib.load(path).get_data()\n",
    "\n",
    "path = '../HGG/Brats17_2013_2_1/Brats17_2013_2_1_t1ce.nii'\n",
    "t1ce_img = nib.load(path).get_data()\n",
    "\n",
    "path = '../HGG/Brats17_2013_2_1/Brats17_2013_2_1_seg.nii'\n",
    "seg_img = nib.load(path).get_data()\n",
    "\n",
    "img = np.zeros((4, 240, 240, 155))\n",
    "img[0,:,:,:] = flair_img\n",
    "img[1,:,:,:] = t1_img\n",
    "img[2,:,:,:] = t2_img\n",
    "img[3,:,:,:] = t1ce_img\n",
    "\n",
    "img = img[:,:,:,:-3]\n",
    "\n",
    "# show_multimodal(img)\n",
    "seg_out = np.zeros((5,240,240,152))\n",
    "seg_img = seg_img[:,:,:-3]\n",
    "\n",
    "for i in range(4):\n",
    "    seg_out[i,:,:,:] = np.equal(seg_img,i)\n",
    "    \n",
    "print(seg_out.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Compress files into numpy compressed form --- maybe use later\n",
    "# i = 0\n",
    "# for root, dirs, files in os.walk('../HGG/'):\n",
    "#     if len(files) > 1:\n",
    "#         HGGnp = np.zeros((4,240,240,155))\n",
    "\n",
    "#         flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "#         HGGnp[0,:,:,:] = flair_img\n",
    "        \n",
    "#         seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "#         HGGsegnp = seg\n",
    "        \n",
    "#         t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "#         HGGnp[1,:,:,:] = flair_img\n",
    "        \n",
    "#         t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "#         HGGnp[2,:,:,:] = flair_img\n",
    "        \n",
    "#         t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "#         HGGnp[3,:,:,:] = flair_img\n",
    "        \n",
    "#         np.savez_compressed(root + '/' + files[-1][:-7], img = HGGnp, seg = HGGsegnp)\n",
    "        \n",
    "#         i +=1\n",
    "#         print(i)\n",
    "\n",
    "\n",
    "# # HGG = tf.Variable(tf.stack(HGGnp), name=\"HGG\", trainable=False)\n",
    "\n",
    "# i = 0\n",
    "# for root, dirs, files in os.walk('../LGG/'):\n",
    "#     if len(files) > 1:\n",
    "#         LGGnp = np.zeros((4,240,240,155))\n",
    "\n",
    "#         flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "#         LGGnp[0,:,:,:] = flair_img\n",
    "        \n",
    "#         seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "#         LGGsegnp = seg\n",
    "        \n",
    "#         t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "#         LGGnp[1,:,:,:] = flair_img\n",
    "        \n",
    "#         t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "#         LGGnp[2,:,:,:] = flair_img\n",
    "        \n",
    "#         t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "#         LGGnp[3,:,:,:] = flair_img\n",
    "        \n",
    "#         np.savez_compressed(root + '/' + files[-1][:-7], img = LGGnp, seg = LGGsegnp)\n",
    "        \n",
    "#         i +=1\n",
    "#         print(i)\n",
    "\n",
    "# # LGG = tf.Variable(tf.zeros([75,4,240,240,155]), name=\"LGG\", trainable=False)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LGGnp = np.zeros((75,4,240,240,155))\n",
    "# i = 0\n",
    "# for root, dirs, files in os.walk('../LGG/'):\n",
    "#     if len(files) > 1:\n",
    "#         LGGnp = np.zeros((4,240,240,155))\n",
    "\n",
    "#         flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "#         LGGnp[0,:,:,:] = flair_img\n",
    "        \n",
    "#         seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "#         LGGsegnp = seg\n",
    "        \n",
    "#         t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "#         LGGnp[1,:,:,:] = flair_img\n",
    "        \n",
    "#         t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "#         LGGnp[2,:,:,:] = flair_img\n",
    "        \n",
    "#         t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "#         LGGnp[3,:,:,:] = flair_img\n",
    "        \n",
    "#         np.savez_compressed(root + '/' + files[-1][:-7], img = LGGnp, seg = LGGsegnp)\n",
    "        \n",
    "#         i +=1\n",
    "#         print(i)\n",
    "        \n",
    "# LGG = tf.Variable(tf.stack(LGGnp), name=\"LGG\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data feeding function\n",
    "\n",
    "def BRATSdatafeed(batch_size):\n",
    "    \"\"\"\n",
    "    Generate training batches for the BRATS data\n",
    "    \n",
    "    The image resizing is done as follows:\n",
    "        - 40 slices removed from beginning and end of dims 0 and 1\n",
    "        - 4 removed from start and 7 removed from end of dim 2\n",
    "        - Image futher downsampled via mean pooling at beginning of CNN\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    inds = np.random.randint(1, 256, batch_size)\n",
    "    \n",
    "    inData = np.zeros((batch_size,160,160,144,4))\n",
    "    labelData = np.zeros((batch_size,160,160,144,5))\n",
    "    \n",
    "    for root, dirs, files in os.walk('../HGG/'):\n",
    "        if (j>=batch_size):\n",
    "            break\n",
    "        if (i < 190) and (len(files) > 1) and (i==inds[j]): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            \n",
    "            j+= 1\n",
    "            \n",
    "        \n",
    "        i +=1\n",
    "        \n",
    "        \n",
    "    for root, dirs, files in os.walk('../LGG/'):\n",
    "        if (j>=batch_size):\n",
    "            break\n",
    "        if (len(files) > 1) and (i==inds[j]): \n",
    "            flair_img = nib.load(root + '/' + files[-5]).get_data()\n",
    "            inData[j,:,:,:,0] = flair_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1_img = nib.load(root + '/' + files[-3]).get_data()\n",
    "            inData[j,:,:,:,1] = t1_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t1ce_img = nib.load(root + '/' + files[-2]).get_data()\n",
    "            inData[j,:,:,:,2] = t1ce_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            t2_img = nib.load(root + '/' + files[-1]).get_data()\n",
    "            inData[j,:,:,:,3] = t2_img[40:-40,40:-40,4:-7]\n",
    "\n",
    "            seg = nib.load(root + '/' + files[-4]).get_data()\n",
    "            seg_img = seg\n",
    "            \n",
    "            for i in range(5):\n",
    "                labelData[j,:,:,:,i] = np.equal(seg_img[40:-40,40:-40,4:-7],i)\n",
    "            \n",
    "            j+= 1\n",
    "            \n",
    "        \n",
    "        i +=1\n",
    "    \n",
    "    x = inData#.reshape([-1,160*160*144*4])\n",
    "    y = labelData.reshape([-1,160*160*144*5])\n",
    "#     x = tf.convert_to_tensor(inData)\n",
    "#     x = tf.reshape(x,[-1,240*240*152*4])\n",
    "#     y = tf.convert_to_tensor(labelData)\n",
    "#     y = tf.reshape(y,[-1,240*240*152*5])\n",
    "    \n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 18432000)\n"
     ]
    }
   ],
   "source": [
    "# Test data feed function\n",
    "x, y = BRATSdatafeed(20)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dice Loss\n",
    "def DICEscore(yFull, prediction):\n",
    "    #\n",
    "    # truth, estimate = tf tensors of size N x voxels*channels\n",
    "    # Computes average Dice scores\n",
    "    #\n",
    "    # loss = scalar tensor containing Dice loss \n",
    "    # \n",
    "    \n",
    "    \n",
    "            \n",
    "    score1 = 2*tf.reduce_mean(tf.divide(tf.reduce_sum(tf.multiply(truth,estimate),axis=1),\n",
    "                       (tf.reduce_sum(truth,axis=1) + tf.reduce_sum(estimate,axis=1))))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def brainconvnet(x):\n",
    "    \"\"\"Funciton to run the computational graph\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor of flattened input images, shape [batch_size, #voxels * 4]\n",
    "    IMPORTANT: \n",
    "        -x must be a channels-first tensor (before resizing)\n",
    "        -remove BOTTOM three slices of x before passing in --- bottom three layers will not contain\n",
    "            much information and this makes sizing much easier within the network\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with shape [batch_size, #voxels * 5]\n",
    "    (Graph calculates 5th order tensor: channel 1 for image, channel 2 for class, others for voxels)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"convNet\") as scope:\n",
    "        input_size = x.get_shape().as_list()\n",
    "#         x_reshape = tf.reshape(x, [-1,160,160,144,4])\n",
    "#         print(input_size)\n",
    "        x_downsample = tf.layers.average_pooling3d(inputs = x, pool_size = (2,2,2),\n",
    "                                        strides = (2,2,2), padding='valid',name=None)\n",
    "#         print(x_downsample.get_shape())\n",
    "        conv1 = tf.layers.conv3d(inputs=x_downsample, filters=8, \n",
    "                                 kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n",
    "        pool1 = tf.layers.max_pooling3d(inputs = conv1, pool_size = (2,2,2),\n",
    "                                        strides = (2,2,2), padding='valid',name=None)\n",
    "#         print(pool1.get_shape())\n",
    "        conv2 = tf.layers.conv3d(inputs=pool1, filters=8, \n",
    "                                 kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n",
    "        pool2 = tf.layers.max_pooling3d(inputs = conv2, pool_size = (2,2,2),\n",
    "                                        strides = (2,2,2), padding='valid',name=None)\n",
    "#         print(pool2.get_shape())\n",
    "        conv3 = tf.layers.conv3d(inputs=pool2, filters=32, \n",
    "                                 kernel_size=[3, 3, 3],padding=\"same\", activation=tf.nn.relu)\n",
    "        pool3 = tf.layers.max_pooling3d(inputs = conv3, pool_size = (2,2,2),\n",
    "                                        strides = (2,2,2), padding='valid',name=None)\n",
    "#         print(pool3.get_shape())\n",
    "        conv4 = tf.layers.conv3d(inputs=pool3, filters=128, \n",
    "                                 kernel_size=[3, 3, 3],padding=\"same\", activation=tf.nn.relu)\n",
    "#         print(conv4.get_shape())\n",
    "#         return conv4\n",
    "            \n",
    "    with tf.variable_scope(\"deconvNet\") as scope:\n",
    "        W4 = tf.Variable(tf.truncated_normal([3, 3, 3, 16, 128], stddev=0.1))\n",
    "        deconv4 = tf.nn.conv3d_transpose(conv4, filter = W4, output_shape = [input_size[0],20, 20, 18, 16], \n",
    "                                         strides = [1,2,2,2,1])\n",
    "#         deconv4 = tf.layers.conv3d_transpose(conv4, filters = 16, kernel_size = [3,3,3], strides = (2,2,2))\n",
    "        b4 = tf.Variable(tf.constant(0.1, shape=[16]))\n",
    "        relu4 = tf.nn.relu(deconv4 + b4)\n",
    "#         print(relu4.get_shape())\n",
    "        \n",
    "        W3 = tf.Variable(tf.truncated_normal([3, 3, 3, 8, 16], stddev=0.1))\n",
    "        deconv3 = tf.nn.conv3d_transpose(relu4, filter = W3, output_shape = [input_size[0],40, 40, 36, 8], \n",
    "                                         strides = [1,2,2,2,1])\n",
    "        b3 = tf.Variable(tf.constant(0.1, shape=[8]))\n",
    "        relu3 = tf.nn.relu(deconv3 + b3)\n",
    "#         print(relu3.get_shape())\n",
    "        \n",
    "        W2 = tf.Variable(tf.truncated_normal([3, 3, 3, 8, 8], stddev=0.1))\n",
    "        deconv2 = tf.nn.conv3d_transpose(relu3, filter = W2, output_shape = [input_size[0],80, 80, 72, 8], \n",
    "                                         strides = [1,2,2,2,1])\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[8]))\n",
    "        relu2 = tf.nn.relu(deconv2 + b2)\n",
    "#         print(relu2.get_shape())\n",
    "        \n",
    "        W1 = tf.Variable(tf.truncated_normal([3, 3, 3, 5, 8], stddev=0.1))\n",
    "        deconv1 = tf.nn.conv3d_transpose(relu2, filter = W1, output_shape = [input_size[0],160, 160, 144, 5], \n",
    "                                         strides = [1,2,2,2,1])\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=[5]))\n",
    "        img = tf.reshape(deconv1 + b1,[input_size[0],5*160*160*144])\n",
    "#         print(img.get_shape())\n",
    "        \n",
    "        return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191277\n"
     ]
    }
   ],
   "source": [
    "# Get number of network parameters\n",
    "def paramcount():\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with get_session() as sess:\n",
    "        y = brainconvnet(tf.ones((2, 160,160,144,4)))\n",
    "        cur_count = count_params()\n",
    "        return cur_count\n",
    "\n",
    "print(paramcount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value convNet/conv3d/kernel\n\t [[Node: convNet/conv3d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@convNet/conv3d/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](convNet/conv3d/kernel)]]\n\nCaused by op u'convNet/conv3d/kernel/read', defined at:\n  File \"/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-158-9f9245bbd1ea>\", line 14, in <module>\n    logits = brainconvnet(inputPlaceholder)\n  File \"<ipython-input-155-b3ae0a13e5bd>\", line 23, in brainconvnet\n    kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 688, in conv3d\n    return layer.apply(inputs)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 286, in __call__\n    self.build(input_shapes[0])\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 138, in build\n    dtype=self.dtype)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 349, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 275, in variable_getter\n    variable_getter=functools.partial(getter, **kwargs))\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 228, in _add_variable\n    trainable=trainable and self.trainable)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 714, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 316, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value convNet/conv3d/kernel\n\t [[Node: convNet/conv3d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@convNet/conv3d/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](convNet/conv3d/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-9f9245bbd1ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     loss, _ = sess.run([segLoss, segSolve],\n\u001b[0;32m---> 21\u001b[0;31m                             feed_dict=feed)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value convNet/conv3d/kernel\n\t [[Node: convNet/conv3d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@convNet/conv3d/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](convNet/conv3d/kernel)]]\n\nCaused by op u'convNet/conv3d/kernel/read', defined at:\n  File \"/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-158-9f9245bbd1ea>\", line 14, in <module>\n    logits = brainconvnet(inputPlaceholder)\n  File \"<ipython-input-155-b3ae0a13e5bd>\", line 23, in brainconvnet\n    kernel_size=[5, 5, 5],padding=\"same\", activation=tf.nn.relu)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 688, in conv3d\n    return layer.apply(inputs)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 286, in __call__\n    self.build(input_shapes[0])\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 138, in build\n    dtype=self.dtype)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 349, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 275, in variable_getter\n    variable_getter=functools.partial(getter, **kwargs))\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 228, in _add_variable\n    trainable=trainable and self.trainable)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 714, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 316, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value convNet/conv3d/kernel\n\t [[Node: convNet/conv3d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@convNet/conv3d/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](convNet/conv3d/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "# Build graph for the network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with get_session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    inputPlaceholder = tf.placeholder(tf.float32, shape = [5, 160,160,144,4])\n",
    "    outputPlaceholder = tf.placeholder(tf.float32, shape = [5, 160*160*144*5])\n",
    "    x, y = BRATSdatafeed(5)\n",
    "#     print(x.shape)\n",
    "    \n",
    "    logits = brainconvnet(inputPlaceholder)\n",
    "    segLoss = tf.reduce_mean(tf.losses.softmax_cross_entropy(outputPlaceholder , logits))\n",
    "    segSolve = tf.train.AdamOptimizer(learning_rate = 1e-3, beta1 = 0.5).minimize(segLoss)\n",
    "    \n",
    "    feed = {inputPlaceholder: x, outputPlaceholder: y}\n",
    "    \n",
    "    loss, _ = sess.run([segLoss, segSolve],\n",
    "                            feed_dict=feed)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# batch_size = 20\n",
    "\n",
    "# placeholders for images from the training dataset\n",
    "# batch_size = tf.placeholder(tf.int32)\n",
    "\n",
    "\n",
    "# segvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'brainconvnet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-4b046617db10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputPlaceholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPlaceholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegSolve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDICEscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "losses = []\n",
    "bdices = []\n",
    "\n",
    "numEpoch = 1\n",
    "batch_size = 5\n",
    "numBatches = np.int(np.ceil(256 / batch_size * numEpoch))\n",
    "\n",
    "\n",
    "for batch in range(numBatches):\n",
    "    x, y = BRATSdatafeed(batch_size)\n",
    "    feed = {inputPlaceholder: x, outputPlaceholder: y}\n",
    "\n",
    "    pred, loss = sess.run(segSolve,feed_dict=feed)\n",
    "    losses.append(loss)\n",
    "    bdice = DICEscore(y, pred)\n",
    "    bdices.append(bdice)\n",
    "    print(\"DICE Score: %s, Loss: %s\" % (bdice,loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
